# Projeto-Final-do-Bootcamp-CDIA

# üîß Sistema de Manuten√ß√£o Preditiva para M√°quinas Industriais

## üìã Descri√ß√£o do Projeto
Este projeto implementa um sistema inteligente de **manuten√ß√£o preditiva** utilizando dados de sensores IoT para prever diferentes tipos de falhas em m√°quinas industriais.  
A solu√ß√£o aplica t√©cnicas de **pr√©-processamento, an√°lise explorat√≥ria de dados (EDA)** e **modelagem de Machine Learning** com m√∫ltiplos algoritmos para classificar falhas espec√≠ficas.

---

## üéØ Objetivo
- Identificar padr√µes em sensores industriais que indicam poss√≠veis falhas.  
- Prever falhas m√∫ltiplas em equipamentos de forma simult√¢nea.  
- Reduzir tempo de inatividade e custos de manuten√ß√£o com t√©cnicas preditivas.  

---

## üìä Dataset
- Fonte: `bootcamp_train.csv`
- Registros: **35.260 amostras**  
- Features: **15 colunas** (sensores, par√¢metros operacionais e falhas).  
- Targets (falhas a serem previstas):
  - **FDF** ‚Äì Falha por Desgaste da Ferramenta  
  - **FDC** ‚Äì Falha por Dissipa√ß√£o de Calor  
  - **FP** ‚Äì Falha por Pot√™ncia  
  - **FTE** ‚Äì Falha por Tens√£o Excessiva  
  - **FA** ‚Äì Falha Aleat√≥ria  

### Exemplo de Features:
- `temperatura_ar`  
- `temperatura_processo`  
- `umidade_relativa`  
- `velocidade_rotacional`  
- `torque`  
- `desgaste_da_ferramenta`  

---

## üõ†Ô∏è Tecnologias Utilizadas
- **Python 3.x**  
- **Bibliotecas principais**:
  - `pandas`, `numpy` ‚Äì manipula√ß√£o de dados  
  - `matplotlib`, `seaborn` ‚Äì visualiza√ß√£o  
  - `scikit-learn` ‚Äì modelagem e m√©tricas  
  - `xgboost`, `lightgbm`, `catboost` ‚Äì modelos de boosting  
  - `imblearn` ‚Äì t√©cnicas de balanceamento (SMOTE, undersampling)  

---

## üîç Etapas do Projeto
1. **An√°lise Explorat√≥ria de Dados (EDA)**  
   - Verifica√ß√£o de nulos, inconsist√™ncias e outliers.  
   - Distribui√ß√£o e correla√ß√£o entre vari√°veis.  
   - Detec√ß√£o de desbalanceamento severo das classes.  

2. **Pr√©-Processamento**  
   - Limpeza de valores inconsistentes.  
   - Imputa√ß√£o de valores ausentes (mediana/moda).  
   - Codifica√ß√£o de vari√°veis categ√≥ricas.  
   - Normaliza√ß√£o das features.  

3. **Divis√£o dos Dados**  
   - Treino (80%) e Teste (20%), com estratifica√ß√£o para manter distribui√ß√£o.  

4. **Modelagem de Machine Learning**  
   - Modelos testados:
     - **Random Forest**  
     - **Gradient Boosting**  
     - **XGBoost**  
     - **LightGBM**  
     - **CatBoost**  
   - Utiliza√ß√£o de **MultiOutputClassifier** para prever m√∫ltiplas falhas.  

5. **Avalia√ß√£o**  
   - M√©tricas utilizadas:  
     - Acur√°cia  
     - Precis√£o  
     - Recall  
     - F1-Score  
     - ROC AUC  
   - Avalia√ß√£o feita **por classe** e **m√©dia das m√©tricas**.  

---

## üìà Resultados
- Os modelos apresentaram **alta acur√°cia geral (>99%)**, mas devido ao **forte desbalanceamento** das classes de falhas, m√©tricas como Recall e F1-Score foram baixas para falhas mais raras.  
- **XGBoost** e **LightGBM** mostraram desempenho mais robusto em Recall e ROC AUC comparado aos demais.  
- A detec√ß√£o de falhas m√∫ltiplas foi rara (**0.05% dos casos**).  

---

## üöÄ Poss√≠veis Melhorias
- Aplicar **t√©cnicas avan√ßadas de balanceamento** (SMOTE combinado com undersampling).  
- Realizar **tuning de hiperpar√¢metros** com GridSearch ou Optuna.  
- Testar arquiteturas de **Deep Learning (LSTM, Autoencoders)** para s√©ries temporais.  
- Implementar um **pipeline automatizado** para deploy em ambiente de produ√ß√£o (ex.: Flask, FastAPI).  

---
## üìä Resultados e An√°lises

### Matriz de Confus√£o
![Matriz de Confus√£o](img/matriz_confusao.png)

### Import√¢ncia das Features
![Import√¢ncia das Features](img/feature_importance.png)

### Curva ROC
![Curva ROC](img/curva_roc.png)
