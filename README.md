# ğŸ”§ Sistema de ManutenÃ§Ã£o Preditiva para MÃ¡quinas Industriais  
**Projeto Final do Bootcamp CDIA**  

## ğŸ“‹ DescriÃ§Ã£o do Projeto  
Este projeto implementa um sistema inteligente de **manutenÃ§Ã£o preditiva** utilizando dados de sensores IoT para prever diferentes tipos de falhas em mÃ¡quinas industriais.  

A soluÃ§Ã£o envolve:  
- **AnÃ¡lise ExploratÃ³ria de Dados (EDA)**  
- **PrÃ©-processamento** (limpeza, imputaÃ§Ã£o, normalizaÃ§Ã£o e codificaÃ§Ã£o)  
- **Modelagem de Machine Learning** com mÃºltiplos algoritmos  
- **AvaliaÃ§Ã£o comparativa de desempenho**  

---

## ğŸ¯ Objetivos  
- Identificar padrÃµes em sensores industriais que indicam possÃ­veis falhas.  
- Prever **falhas mÃºltiplas** de forma simultÃ¢nea.  
- Reduzir **tempo de inatividade** e **custos de manutenÃ§Ã£o**.  

---

## ğŸ“Š Dataset  
- **Fonte:** `bootcamp_train.csv`  
- **Registros:** 35.260 amostras  
- **Features:** 15 variÃ¡veis (sensores, parÃ¢metros operacionais e falhas)  
- **Targets (falhas a serem previstas):**  
  - `FDF` â€“ Falha por Desgaste da Ferramenta  
  - `FDC` â€“ Falha por DissipaÃ§Ã£o de Calor  
  - `FP` â€“ Falha por PotÃªncia  
  - `FTE` â€“ Falha por TensÃ£o Excessiva  
  - `FA` â€“ Falha AleatÃ³ria  

### Exemplo de Features  
- `temperatura_ar`  
- `temperatura_processo`  
- `umidade_relativa`  
- `velocidade_rotacional`  
- `torque`  
- `desgaste_da_ferramenta`  

---

## ğŸ› ï¸ Tecnologias Utilizadas  
- **Python 3.x**  
- **Bibliotecas:**  
  - `pandas`, `numpy` â†’ manipulaÃ§Ã£o de dados  
  - `matplotlib`, `seaborn` â†’ visualizaÃ§Ã£o  
  - `scikit-learn` â†’ modelagem e mÃ©tricas  
  - `xgboost`, `lightgbm`, `catboost` â†’ algoritmos de boosting  
  - `imblearn` â†’ tÃ©cnicas de balanceamento (SMOTE, undersampling)  

---

## ğŸ” Etapas do Projeto  
1. **EDA**  
   - VerificaÃ§Ã£o de nulos e inconsistÃªncias.  
   - DistribuiÃ§Ã£o das variÃ¡veis e correlaÃ§Ã£o.  
   - AnÃ¡lise do desbalanceamento das classes.  

2. **PrÃ©-Processamento**  
   - Limpeza de inconsistÃªncias (`sim`, `nÃ£o`, `0`, `1`, `y` etc.).  
   - ImputaÃ§Ã£o de valores ausentes (mediana/moda).  
   - NormalizaÃ§Ã£o com **StandardScaler**.  
   - CodificaÃ§Ã£o da variÃ¡vel categÃ³rica `tipo`.  

3. **DivisÃ£o dos Dados**  
   - 80% treino | 20% teste (estratificado).  

4. **Modelagem**  
   - Algoritmos avaliados:  
     - ğŸŒ² Random Forest  
     - ğŸŒ Gradient Boosting  
     - âš¡ XGBoost  
     - ğŸ”¥ LightGBM  
     - ğŸ± CatBoost  
   - Uso de **MultiOutputClassifier** para prever falhas mÃºltiplas.  

5. **AvaliaÃ§Ã£o**  
   - MÃ©tricas: AcurÃ¡cia, PrecisÃ£o, Recall, F1-Score e ROC AUC.  
   - AvaliaÃ§Ã£o **por classe** e **mÃ©dia ponderada**.  

---

## ğŸ“Š AnÃ¡lise ExploratÃ³ria dos Dados  
- **Valores nulos:** presentes em variÃ¡veis como `temperatura_ar`, `torque`, `desgaste_da_ferramenta`.  
- **Classes desbalanceadas:** algumas falhas representam **menos de 1% dos dados**.  
- **Outliers:** encontrados em temperatura, velocidade rotacional e torque.  

### VisualizaÃ§Ãµes  
- DistribuiÃ§Ã£o das Features NumÃ©ricas  
<img width="1494" height="990" alt="DistribuiÃ§Ã£o das VariÃ¡veis" src="https://github.com/user-attachments/assets/106915fd-a516-481a-9cf9-a4461d59cf4e" />  

- Matriz de CorrelaÃ§Ã£o  
<img width="1366" height="663" alt="Matriz de CorrelaÃ§Ã£o" src="https://github.com/user-attachments/assets/bf98be17-69a9-4e4d-90be-2ac3dfdf50a7" />  

- Desbalanceamento das Classes  
<img width="1366" height="663" alt="Desbalanceamento" src="https://github.com/user-attachments/assets/8f5c823e-a2b7-48ac-820a-78b70a903dad" />  

**Percentual de falhas positivas:**  
- FDF: 0.20%  
- FDC: 0.63%  
- FP: 0.36%  
- FTE: 0.48%  
- FA: 0.21%  

ğŸ‘‰ **ConclusÃ£o inicial:** dataset altamente desbalanceado â†’ modelos tendem a alta acurÃ¡cia e baixo recall.  

---

## ğŸ¤– Resultados Obtidos  

### ğŸ” Desempenho MÃ©dio por Modelo  
| Modelo            | AcurÃ¡cia | PrecisÃ£o | Recall | F1-Score | ROC AUC |
|------------------|----------|----------|--------|----------|---------|
| Random Forest     | 0.9966   | 0.4305   | 0.1671 | 0.2318   | 0.5831  |
| Gradient Boosting | 0.9963   | 0.3810   | 0.1785 | 0.2423   | 0.5882  |
| XGBoost           | 0.9966   | 0.5097   | 0.1968 | 0.2722   | 0.5975  |
| LightGBM          | 0.9963   | 0.4476   | 0.1802 | 0.2502   | 0.5897  |
| CatBoost          | 0.9964   | 0.4643   | 0.1833 | 0.2562   | 0.5913  |

### ğŸ“‰ Detalhe do Melhor Modelo (XGBoost)  
| Falha | AcurÃ¡cia | PrecisÃ£o | Recall | F1-Score | ROC AUC |
|-------|----------|----------|--------|----------|---------|
| FDF   | 0.998    | 0.500    | 0.014  | 0.027    | 0.507   |
| FDC   | 0.994    | 0.571    | 0.202  | 0.299    | 0.601   |
| FP    | 0.997    | 0.667    | 0.044  | 0.083    | 0.522   |
| FTE   | 0.996    | 0.400    | 0.024  | 0.045    | 0.512   |
| FA    | 0.998    | 0.500    | 0.005  | 0.010    | 0.502   |

> ğŸ” Apesar da alta acurÃ¡cia, o recall Ã© baixo para classes minoritÃ¡rias â†’ indicando que falhas raras ainda nÃ£o sÃ£o bem detectadas.  

---

## ğŸš€ PossÃ­veis Melhorias  
- Balanceamento avanÃ§ado: **SMOTE + undersampling**.  
- OtimizaÃ§Ã£o com **GridSearchCV** ou **Optuna**.  
- Testar **Deep Learning (LSTM, Autoencoders)** para sÃ©ries temporais.  
- Pipeline automatizado para **deploy em produÃ§Ã£o** (Flask/FastAPI).  

---

## ğŸ“Œ ConclusÃµes  
- O projeto mostrou que, embora a acurÃ¡cia seja altÃ­ssima (>99%), isso se deve ao **forte desbalanceamento**.  
- **XGBoost** foi o algoritmo mais equilibrado, mas ainda com recall baixo para falhas raras.  
- Futuras melhorias devem focar em **balanceamento das classes** e em **mÃ©tricas robustas** alÃ©m da acurÃ¡cia.  

---

âœï¸ Autor: **Adilson**  
ğŸ“… Projeto Final â€“ Bootcamp CDIA  
