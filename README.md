# Projeto-Final-do-Bootcamp-CDIA

# üîß Sistema de Manuten√ß√£o Preditiva para M√°quinas Industriais

## üìã Descri√ß√£o do Projeto
Este projeto implementa um sistema inteligente de **manuten√ß√£o preditiva** utilizando dados de sensores IoT para prever diferentes tipos de falhas em m√°quinas industriais.  
A solu√ß√£o aplica t√©cnicas de **pr√©-processamento, an√°lise explorat√≥ria de dados (EDA)** e **modelagem de Machine Learning** com m√∫ltiplos algoritmos para classificar falhas espec√≠ficas.

---

## üéØ Objetivo
- Identificar padr√µes em sensores industriais que indicam poss√≠veis falhas.  
- Prever falhas m√∫ltiplas em equipamentos de forma simult√¢nea.  
- Reduzir tempo de inatividade e custos de manuten√ß√£o com t√©cnicas preditivas.  

---

## üìä Dataset
- Fonte: `bootcamp_train.csv`
- Registros: **35.260 amostras**  
- Features: **15 colunas** (sensores, par√¢metros operacionais e falhas).  
- Targets (falhas a serem previstas):
  - **FDF** ‚Äì Falha por Desgaste da Ferramenta  
  - **FDC** ‚Äì Falha por Dissipa√ß√£o de Calor  
  - **FP** ‚Äì Falha por Pot√™ncia  
  - **FTE** ‚Äì Falha por Tens√£o Excessiva  
  - **FA** ‚Äì Falha Aleat√≥ria  

### Exemplo de Features:
- `temperatura_ar`  
- `temperatura_processo`  
- `umidade_relativa`  
- `velocidade_rotacional`  
- `torque`  
- `desgaste_da_ferramenta`  

---

## üõ†Ô∏è Tecnologias Utilizadas
- **Python 3.x**  
- **Bibliotecas principais**:
  - `pandas`, `numpy` ‚Äì manipula√ß√£o de dados  
  - `matplotlib`, `seaborn` ‚Äì visualiza√ß√£o  
  - `scikit-learn` ‚Äì modelagem e m√©tricas  
  - `xgboost`, `lightgbm`, `catboost` ‚Äì modelos de boosting  
  - `imblearn` ‚Äì t√©cnicas de balanceamento (SMOTE, undersampling)  

---

## üîç Etapas do Projeto
1. **An√°lise Explorat√≥ria de Dados (EDA)**  
   - Verifica√ß√£o de nulos, inconsist√™ncias e outliers.  
   - Distribui√ß√£o e correla√ß√£o entre vari√°veis.  
   - Detec√ß√£o de desbalanceamento severo das classes.  

2. **Pr√©-Processamento**  
   - Limpeza de valores inconsistentes.  
   - Imputa√ß√£o de valores ausentes (mediana/moda).  
   - Codifica√ß√£o de vari√°veis categ√≥ricas.  
   - Normaliza√ß√£o das features.  

3. **Divis√£o dos Dados**  
   - Treino (80%) e Teste (20%), com estratifica√ß√£o para manter distribui√ß√£o.  

4. **Modelagem de Machine Learning**  
   - Modelos testados:
     - **Random Forest**  
     - **Gradient Boosting**  
     - **XGBoost**  
     - **LightGBM**  
     - **CatBoost**  
   - Utiliza√ß√£o de **MultiOutputClassifier** para prever m√∫ltiplas falhas.  

5. **Avalia√ß√£o**  
   - M√©tricas utilizadas:  
     - Acur√°cia  
     - Precis√£o  
     - Recall  
     - F1-Score  
     - ROC AUC  
   - Avalia√ß√£o feita **por classe** e **m√©dia das m√©tricas**.  

---

## üìà Resultados
- Os modelos apresentaram **alta acur√°cia geral (>99%)**, mas devido ao **forte desbalanceamento** das classes de falhas, m√©tricas como Recall e F1-Score foram baixas para falhas mais raras.  
- **XGBoost** e **LightGBM** mostraram desempenho mais robusto em Recall e ROC AUC comparado aos demais.  
- A detec√ß√£o de falhas m√∫ltiplas foi rara (**0.05% dos casos**).  

---

## üöÄ Poss√≠veis Melhorias
- Aplicar **t√©cnicas avan√ßadas de balanceamento** (SMOTE combinado com undersampling).  
- Realizar **tuning de hiperpar√¢metros** com GridSearch ou Optuna.  
- Testar arquiteturas de **Deep Learning (LSTM, Autoencoders)** para s√©ries temporais.  
- Implementar um **pipeline automatizado** para deploy em ambiente de produ√ß√£o (ex.: Flask, FastAPI).  

---
## üìä An√°lise Explorat√≥ria dos Dados

- **Tamanho do dataset**: 35.260 amostras e 15 colunas  
- **Valores nulos**: presentes em vari√°veis num√©ricas (`temperatura_ar`, `torque`, `desgaste_da_ferramenta`)  
- **Classes desbalanceadas**: algumas falhas representam **menos de 1% dos dados**  
- **Outliers** detectados em vari√°veis de temperatura, velocidade rotacional e torque  

### Distribui√ß√£o das Features Num√©ricas
![Distribui√ß√£o das Vari√°veis](imagens/distribuicao_variaveis.png)

### Correla√ß√£o entre Vari√°veis
![Matriz de Correla√ß√£o](imagens/matriz_correlacao.png)

### Desbalanceamento das Classes
![Desbalanceamento](imagens/desbalanceamento_classes.png)

- FDF: 0.20% positivos  
- FDC: 0.63% positivos  
- FP: 0.36% positivos  
- FTE: 0.48% positivos  
- FA: 0.21% positivos  

üëâ **Conclus√£o inicial**: dataset altamente desbalanceado ‚Üí risco de modelos com alta acur√°cia mas baixo recall para falhas.

---

## ‚öôÔ∏è Pr√©-processamento

1. Limpeza de inconsist√™ncias (`sim`, `n√£o`, `0`, `1`, `y`, etc.)  
2. Imputa√ß√£o de valores nulos ‚Üí **mediana** para num√©ricos  
3. Normaliza√ß√£o com **StandardScaler**  
4. Codifica√ß√£o da vari√°vel categ√≥rica `tipo`  
5. Divis√£o em **treino (80%)** e **teste (20%)**  

---

## ü§ñ Modelos Avaliados

Foram avaliados os seguintes classificadores em **configura√ß√£o MultiOutput**:

- üå≤ Random Forest  
- üåê Gradient Boosting  
- ‚ö° XGBoost  
- üî• LightGBM  
- üê± CatBoost  

---

## üìà Resultados

### Random Forest
- Acur√°cia M√©dia: **0.9966**  
- Precis√£o M√©dia: **0.4305**  
- Recall M√©dio: **0.1671**  
- F1-Score M√©dio: **0.2318**

### Gradient Boosting
- Acur√°cia M√©dia: **0.9963**  
- Precis√£o M√©dia: **0.3810**  
- Recall M√©dio: **0.1785**  
- F1-Score M√©dio: **0.2423**

### XGBoost
- Acur√°cia M√©dia: **0.9966**  
- Precis√£o M√©dia: **0.5097**  
- Recall M√©dio: **0.1968**  
- F1-Score M√©dio: **0.2722**

### LightGBM
- Acur√°cia M√©dia: **0.9963**  
- Resultados similares ao XGBoost, mas com menor recall em algumas classes  

### CatBoost
- [Resultados ainda em execu√ß√£o ou a incluir aqui]  

---

## üìä Compara√ß√£o entre Modelos
| Modelo            | Acur√°cia M√©dia | Precis√£o M√©dia | Recall M√©dio | F1-Score M√©dio |
|-------------------|----------------|----------------|--------------|----------------|
| Random Forest     | 0.9966         | 0.4305         | 0.1671       | 0.2318         |
| Gradient Boosting | 0.9963         | 0.3810         | 0.1785       | 0.2423         |
| XGBoost           | 0.9966         | 0.5097         | 0.1968       | 0.2722         |
| LightGBM          | 0.9963         | ~0.45          | ~0.18        | ~0.25          |
| CatBoost          | ‚Äî              | ‚Äî              | ‚Äî            | ‚Äî              |

---

## üìå Conclus√µes
- Apesar da **alta acur√°cia**, os modelos apresentaram **baixo recall e F1-score** devido ao **forte desbalanceamento das classes**.  
- **XGBoost** teve o melhor equil√≠brio entre precis√£o e recall.  
- Recomenda-se aplicar t√©cnicas de **oversampling (SMOTE)** ou **undersampling** para melhorar o desempenho nas classes minorit√°rias.  
- Futuras otimiza√ß√µes podem incluir **ajuste de hiperpar√¢metros via GridSearchCV** e uso de **m√©tricas ponderadas**.

‚úçÔ∏è Autor: Adilson | Projeto Final Bootcamp CDIA
---
